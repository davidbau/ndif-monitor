{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generation Test\n",
    "\n",
    "Tests text generation with `model.generate()` through NDIF.\n",
    "\n",
    "**Environment Variables:**\n",
    "- `MODEL_NAME`: Model to test\n",
    "- `NDIF_API`: NDIF API key\n",
    "- `HF_TOKEN`: HuggingFace token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "\n",
    "MODEL_NAME = os.environ.get(\"MODEL_NAME\", \"openai-community/gpt2\")\n",
    "print(f\"Testing model: {MODEL_NAME}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure NDIF\n",
    "from nnsight import CONFIG\n",
    "\n",
    "NDIF_API = os.environ.get(\"NDIF_API\")\n",
    "if NDIF_API:\n",
    "    CONFIG.set_default_api_key(NDIF_API)\n",
    "    print(\"NDIF API key configured\")\n",
    "\n",
    "HF_TOKEN = os.environ.get(\"HF_TOKEN\")\n",
    "if HF_TOKEN:\n",
    "    os.environ[\"HF_TOKEN\"] = HF_TOKEN\n",
    "    print(\"HF_TOKEN configured\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model\n",
    "from nnsight import LanguageModel\n",
    "\n",
    "print(f\"Loading {MODEL_NAME}...\")\n",
    "start = time.time()\n",
    "model = LanguageModel(MODEL_NAME, device_map=\"auto\")\n",
    "load_time = time.time() - start\n",
    "print(f\"Model loaded in {load_time:.1f}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run generation\n",
    "prompt = \"Once upon a time\"\n",
    "max_new_tokens = 20\n",
    "\n",
    "print(f\"Generating from: '{prompt}'\")\n",
    "print(f\"Max new tokens: {max_new_tokens}\")\n",
    "\n",
    "start = time.time()\n",
    "with model.generate(prompt, max_new_tokens=max_new_tokens, remote=True):\n",
    "    output_ids = model.generator.output.save()\n",
    "\n",
    "gen_time = time.time() - start\n",
    "print(f\"Generation completed in {gen_time:.1f}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decode and validate output\n",
    "output_text = model.tokenizer.decode(output_ids[0], skip_special_tokens=True)\n",
    "print(f\"\\nGenerated text:\\n{output_text}\")\n",
    "\n",
    "# Validate\n",
    "assert len(output_text) > len(prompt), \"Output should be longer than prompt\"\n",
    "assert output_text.startswith(prompt) or prompt.lower() in output_text.lower(), \\\n",
    "    \"Output should contain the prompt\"\n",
    "\n",
    "# Check we got new tokens\n",
    "prompt_tokens = len(model.tokenizer.encode(prompt))\n",
    "output_tokens = len(output_ids[0])\n",
    "new_tokens = output_tokens - prompt_tokens\n",
    "print(f\"\\nPrompt tokens: {prompt_tokens}\")\n",
    "print(f\"Output tokens: {output_tokens}\")\n",
    "print(f\"New tokens: {new_tokens}\")\n",
    "\n",
    "assert new_tokens > 0, \"Should have generated at least 1 new token\"\n",
    "\n",
    "print(\"\\n\" + \"=\" * 40)\n",
    "print(\"GENERATION \" + \"TEST PASSED\")\n",
    "print(\"=\" * 40)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
