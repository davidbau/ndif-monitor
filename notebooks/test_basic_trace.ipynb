{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic Trace Test\n",
    "\n",
    "Tests basic `model.trace()` functionality with hidden state extraction.\n",
    "\n",
    "**Environment Variables:**\n",
    "- `MODEL_NAME`: Model to test (e.g., \"meta-llama/Llama-3.1-8B\")\n",
    "- `NDIF_API`: NDIF API key\n",
    "- `HF_TOKEN`: HuggingFace token (for gated models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "\n",
    "# Get model name from environment\n",
    "MODEL_NAME = os.environ.get(\"MODEL_NAME\", \"openai-community/gpt2\")\n",
    "print(f\"Testing model: {MODEL_NAME}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure NDIF\n",
    "from nnsight import CONFIG\n",
    "\n",
    "NDIF_API = os.environ.get(\"NDIF_API\")\n",
    "if NDIF_API:\n",
    "    CONFIG.set_default_api_key(NDIF_API)\n",
    "    print(\"NDIF API key configured\")\n",
    "else:\n",
    "    print(\"Warning: NDIF_API not set\")\n",
    "\n",
    "# Configure HuggingFace token\n",
    "HF_TOKEN = os.environ.get(\"HF_TOKEN\")\n",
    "if HF_TOKEN:\n",
    "    os.environ[\"HF_TOKEN\"] = HF_TOKEN\n",
    "    print(\"HF_TOKEN configured\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model\n",
    "from nnsight import LanguageModel\n",
    "\n",
    "print(f\"Loading {MODEL_NAME}...\")\n",
    "start = time.time()\n",
    "model = LanguageModel(MODEL_NAME, device_map=\"auto\")\n",
    "load_time = time.time() - start\n",
    "print(f\"Model loaded in {load_time:.1f}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run basic trace - use model name to select correct layer path\n",
    "# NOTE: Variables from outside model.trace() are NOT available on the server!\n",
    "# We must use separate trace blocks per architecture.\n",
    "\n",
    "prompt = \"The quick brown fox\"\n",
    "print(f\"Running trace on: '{prompt}'\")\n",
    "\n",
    "# Detect architecture from model name\n",
    "model_lower = MODEL_NAME.lower()\n",
    "\n",
    "start = time.time()\n",
    "if 'gpt-j' in model_lower or 'gpt2' in model_lower:\n",
    "    # GPT-2, GPT-J: transformer.h\n",
    "    with model.trace(prompt, remote=True):\n",
    "        hidden = model.transformer.h[0].output[0].save()\n",
    "elif 'gpt-neo' in model_lower or 'pythia' in model_lower:\n",
    "    # GPT-NeoX, Pythia: gpt_neox.layers\n",
    "    with model.trace(prompt, remote=True):\n",
    "        hidden = model.gpt_neox.layers[0].output[0].save()\n",
    "else:\n",
    "    # Llama, Mistral, Qwen, OLMo, etc.: model.layers\n",
    "    with model.trace(prompt, remote=True):\n",
    "        hidden = model.model.layers[0].output[0].save()\n",
    "\n",
    "trace_time = time.time() - start\n",
    "print(f\"Trace completed in {trace_time:.1f}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validate results\n",
    "import torch\n",
    "\n",
    "print(f\"Hidden state shape: {hidden.shape}\")\n",
    "print(f\"Hidden state dtype: {hidden.dtype}\")\n",
    "\n",
    "# Verify shape is reasonable\n",
    "assert len(hidden.shape) >= 2, f\"Expected at least 2D tensor, got {hidden.shape}\"\n",
    "assert hidden.shape[-1] > 0, \"Hidden dimension should be positive\"\n",
    "\n",
    "# Check for NaN/Inf\n",
    "assert not torch.isnan(hidden).any(), \"Hidden state contains NaN values\"\n",
    "assert not torch.isinf(hidden).any(), \"Hidden state contains Inf values\"\n",
    "\n",
    "# Check values are reasonable\n",
    "assert hidden.abs().max() < 1000, f\"Hidden values too large: max={hidden.abs().max()}\"\n",
    "\n",
    "print(\"\\n\" + \"=\" * 40)\n",
    "print(\"BASIC TRACE \" + \"TEST PASSED\")\n",
    "print(\"=\" * 40)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
